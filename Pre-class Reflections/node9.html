<!DOCTYPE HTML>

<!--Converted with LaTeX2HTML 2019.2 (Released June 5, 2019) -->
<HTML lang="EN">
<HEAD>
<TITLE>Week 10</TITLE>
<META NAME="description" CONTENT="Week 10">
<META NAME="keywords" CONTENT="Pre-class Reflections">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="viewport" CONTENT="width=device-width, initial-scale=1.0">
<META NAME="Generator" CONTENT="LaTeX2HTML v2019.2">

<LINK REL="STYLESHEET" HREF="Pre-class Reflections.css">

<LINK REL="next" HREF="node10.html">
<LINK REL="previous" HREF="node8.html">
<LINK REL="next" HREF="node10.html">
</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<A
 HREF="node10.html">
<IMG WIDTH="37" HEIGHT="24" ALT="next" SRC="next.png"></A> 
<A
 HREF="Pre-class Reflections.html">
<IMG WIDTH="26" HEIGHT="24" ALT="up" SRC="up.png"></A> 
<A
 HREF="node8.html">
<IMG WIDTH="63" HEIGHT="24" ALT="previous" SRC="prev.png"></A>   
<BR>
<B> Next:</B> <A
 HREF="node10.html">About this document ...</A>
<B> Up:</B> <A
 HREF="Pre-class Reflections.html">CS 309 (Intro to</A>
<B> Previous:</B> <A
 HREF="node8.html">Week 9</A>
<BR>
<BR></DIV>
<!--End of Navigation Panel-->

<H1><A ID="SECTION00090000000000000000">
Week 10</A>
</H1>
Part 1:
Reflect on the ethical concerns presented in this week's videos and/or reading in a paragraph (5-10 sentences). In your paragraph, be sure to:

<UL>
<LI>Clarify the topic/ethical dilemma you are considering;
</LI>
<LI>Consider the perspective of the different stakeholder and the individuals impacted;
</LI>
<LI>Connect the topic to any ethical framework you are aware of that may apply in this situation;
</LI>
<LI>Acknowledge any personal biases you may have with respect to this topic; and
</LI>
<LI>Suggest some practical and ethical solutions.
</LI>
</UL>
Part 2:
Reflecting on the content of this module (including all videos and reading), write a paragraph (5-10 sentences) that includes one or more of the following:

<UL>
<LI>Insightful questions;
</LI>
<LI>Clarification questions about ambiguities;
</LI>
<LI>Comments about the relation of the content to the previous content;
</LI>
<LI>Solutions to problems or exercises posed in the readings or videos;
</LI>
<LI>Critiques;
</LI>
<LI>Thoughts on what you would like to learn about in more detail;
</LI>
<LI>Possible extensions or related studies;
</LI>
<LI>Summaries of the most important things you learned.
</LI>
</UL>
<DIV class="CENTER">

</DIV>
The ethical topic/dilemma that is concerning to me is the determination of a user's privacy when using an LLM or DALL-E like systems; where do the user's right to opt-out from being part of the data set fall on? Via what basis? Nowadays, the modern companies of today have these user's waive their rights via an agreement called the TOS when a user wants to user their service; another form that these modern-day companies try to thwart the efforts of the user from protecting their data is hiding or making it difficult to find the option(s) to opt-out. In addition, companies like OpenAI, Microsoft, Apple, Google, and so many more, are using this practice as a way to "legally" scrape the user's data without the user's knowledge since who nowadays reads the Terms of Service? The topic of determining user privacy in the space of AI, reminds me of the ethical framework of the Rights-based Ethics as the indivudual and really everyone have a natural right(s) that should not be pertrubated by a company or goverment, which fits this topic perfectly. A solution that I suggest for user privacy with an undertone of security is the legality of asking consent of the user, in using their data for training the model and so on in clear terms or a prompt displayed to them so they have to option to deny or agree to these terms. In addition, if the user's data is used via consent; then the company should secure or censor any determining identification of the user when tranining it for the model.

<P>
In this module, I found it interesting how the problem of historical and racial bias is currently the problem plaguing AI due to it's diverse dataset. One of the articles that I read was interesting in what are the recommended actions or frameworks that they recommend in their paper in engineering an LLM system; and the possible harms that those engineers should be aware of when designing their system(s).

<DIV CLASS="navigation"><HR>
<!--Navigation Panel-->
<A
 HREF="node10.html">
<IMG WIDTH="37" HEIGHT="24" ALT="next" SRC="next.png"></A> 
<A
 HREF="Pre-class Reflections.html">
<IMG WIDTH="26" HEIGHT="24" ALT="up" SRC="up.png"></A> 
<A
 HREF="node8.html">
<IMG WIDTH="63" HEIGHT="24" ALT="previous" SRC="prev.png"></A>   
<BR>
<B> Next:</B> <A
 HREF="node10.html">About this document ...</A>
<B> Up:</B> <A
 HREF="Pre-class Reflections.html">CS 309 (Intro to</A>
<B> Previous:</B> <A
 HREF="node8.html">Week 9</A></DIV>
<!--End of Navigation Panel-->

</BODY>
</HTML>
